{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Yke/Desktop/AI/Thesis/ESA/transit-detection-rnn\n"
     ]
    }
   ],
   "source": [
    "if \"descended\" not in locals():\n",
    "    descended = 1\n",
    "    %cd \"..\"\n",
    "    \n",
    "import utils\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from lilith.lilith_utils import *\n",
    "\n",
    "from wotan import flatten\n",
    "import visualize as vis\n",
    "\n",
    "from dataloading import loading as dl\n",
    "\n",
    "from detection import bls_detection as bls_det\n",
    "from detection import rnn_detection as rnn_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dvdic(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        dvdic = pickle.load(f)\n",
    "    return dvdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_all = read_dvdic(\"data/lilith/dv/dv_dic.pkl\")\n",
    "dv_sect = {}\n",
    "for i in [1,2,3,4]:\n",
    "    dv_sect[i] = read_dvdic(f\"data/lilith/sector{i}/dv/dv_dic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1256, 498, 601, 592, 490)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dv_all), len(dv_sect[1]), len(dv_sect[2]), len(dv_sect[3]), len(dv_sect[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sampleid 44577667 in (B)EB data not found in sampleids\n",
      "WARNING: sampleid 238196512 in (B)EB data not found in sampleids\n",
      "WARNING: sampleid 238196512 in (B)EB data not found in sampleids\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"data/lilith\"\n",
    "SECTOR = {i:f\"/sector{i}\" for i in [1,2,3,4]}  # use as: path = BASE_PATH + SECTOR[i]\n",
    "[BASE_PATH + \"/\" + dirname for dirname in os.listdir(BASE_PATH) if os.path.isdir(BASE_PATH + \"/\" + dirname)]\n",
    "\n",
    "# load ground-truth and sector sampleids\n",
    "sampleids_sector = {i:sampleids_from_curl(BASE_PATH+SECTOR[i]+'/fits') for i in SECTOR}\n",
    "sampleids = set()\n",
    "for i in SECTOR:\n",
    "    sampleids.update(sampleids_sector[i])\n",
    "sampleids = np.array(list(sampleids))\n",
    "\n",
    "gt_sector = {i:{obj:{} for obj in [\"pl\", \"eb\", \"beb\"]} for i in SECTOR}\n",
    "gt = {obj:{\"params\":{}, \"sampleids\":[]} for obj in [\"pl\", \"eb\", \"beb\"]}\n",
    "for i in SECTOR:\n",
    "    gt_path = BASE_PATH+SECTOR[i]+'/ground_truth'\n",
    "    gt_sector[i][\"pl\"][\"params\"], gt_sector[i][\"pl\"][\"sampleids\"] = get_pl_data(gt_path, sampleids_sector[i])\n",
    "    gt_sector[i][\"eb\"][\"params\"], gt_sector[i][\"eb\"][\"sampleids\"] = get_eb_data(gt_path, sampleids_sector[i], backeb=0)\n",
    "    gt_sector[i][\"beb\"][\"params\"], gt_sector[i][\"beb\"][\"sampleids\"] = get_eb_data(gt_path, sampleids_sector[i], backeb=1)\n",
    "    for obj in [\"pl\", \"eb\", \"beb\"]:\n",
    "        for sampleid, obj_data in gt_sector[i][obj][\"params\"].items():  \n",
    "            if sampleid in gt[obj][\"sampleids\"]:\n",
    "                # ground truth already saved from prev sector\n",
    "                if obj_data != gt[obj][\"params\"][sampleid]:\n",
    "                    print(\"WARNING: inconsistent ground-truth data\")\n",
    "            elif obj_data != {}:\n",
    "                gt[obj][\"params\"][sampleid] = obj_data\n",
    "                gt[obj][\"sampleids\"].append(sampleid)\n",
    "for obj in [\"pl\", \"eb\", \"beb\"]:\n",
    "    gt[obj][\"sampleids\"] = np.array(gt[obj][\"sampleids\"])\n",
    "    for sampleid in sampleids:\n",
    "        if sampleid not in gt[obj][\"sampleids\"]:\n",
    "            gt[obj][\"params\"][sampleid] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select test samples and display statistics\n",
    "test_sampleids = {obj:set() for obj in [\"all\", \"pl\", \"eb\", \"beb\"]}  # not to be used for training\n",
    "\n",
    "def inter(a, b):\n",
    "    return np.intersect1d(a, b)\n",
    "\n",
    "for i1 in SECTOR:\n",
    "    for i2 in SECTOR:\n",
    "        if i2 > i1:\n",
    "            s_ids = inter(sampleids_sector[i1], sampleids_sector[i2])\n",
    "            pl_ids = inter(gt_sector[i1][\"pl\"][\"sampleids\"], gt_sector[i2][\"pl\"][\"sampleids\"])\n",
    "            eb_ids = inter(gt_sector[i1][\"eb\"][\"sampleids\"], gt_sector[i2][\"eb\"][\"sampleids\"])\n",
    "            beb_ids = inter(gt_sector[i1][\"beb\"][\"sampleids\"], gt_sector[i2][\"beb\"][\"sampleids\"])\n",
    "            \n",
    "            test_sampleids[\"all\"].update(s_ids), test_sampleids[\"pl\"].update(pl_ids)\n",
    "            test_sampleids[\"eb\"].update(eb_ids), test_sampleids[\"beb\"].update(beb_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ids_corrected = []\n",
    "for s_id in test_sampleids[\"pl\"]:\n",
    "    if (s_id not in test_sampleids[\"eb\"]) and (s_id not in test_sampleids[\"beb\"]):\n",
    "        pl_ids_corrected.append(s_id)\n",
    "pl_ids_corrected= np.array(pl_ids_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trange(sector):\n",
    "    with open(f\"data/lilith/sector{sector}/raw_batches/test/00000-00249\", \"rb\") as f:\n",
    "        b = pickle.load(f)\n",
    "    return (b[\"time\"][0][0], b[\"time\"][0][-1])\n",
    "sector_range = {i:get_trange(i) for i in [1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consec_sectors(sec_str, only_two=False):\n",
    "    consec = 0\n",
    "    for s in sec_str:\n",
    "        if s==\"1\":\n",
    "            consec += 1\n",
    "        elif consec and s==\"0\":\n",
    "            return False\n",
    "    if only_two:\n",
    "        if consec != 2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def consec_from_data(times, only_two=False):\n",
    "    if len(times)==1:\n",
    "        print(\"WARNING: test sample with only one sector\")\n",
    "    t_cat = np.concatenate(times)\n",
    "    if np.max(np.diff(t_cat))>10:\n",
    "        return False\n",
    "    if only_two and len(times) > 2: \n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def retrieve_sector(time):\n",
    "    midt = np.nanmean(time)\n",
    "    for s in sector_range:\n",
    "        if midt > sector_range[s][0] and midt < sector_range[s][1]:\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:18,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: test sample with only one sector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:13<00:05,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: test sample with only one sector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:18<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: test sample with only one sector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "consec = {}\n",
    "excluded = []\n",
    "pbar = tqdm(os.listdir(\"data/eval/lilith/processed_nn_basic\"))\n",
    "for fname in pbar:\n",
    "    try:\n",
    "        with open(\"data/eval/lilith/processed_nn_basic/\"+fname, \"rb\") as f:\n",
    "            b = pickle.load(f)\n",
    "        for s_id, data in b.items():\n",
    "            if s_id in pl_ids_corrected:\n",
    "                if len(data[\"time\"])==0:\n",
    "                    excluded.append(s_id)\n",
    "                    continue\n",
    "                consec[s_id] = consec2_from_data(data[\"time\"])\n",
    "    except:\n",
    "        pbar.close()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_id in excluded:\n",
    "    keep = pl_ids_corrected!=s_id\n",
    "    pl_ids_corrected = pl_ids_corrected[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_t0(t0, period, sectors, warnings=False):\n",
    "    sectors = sectors if isinstance(sectors, list) else [sectors]\n",
    "    tt = t0\n",
    "    while tt < sector_range[sectors[0]][0]:\n",
    "        tt += period\n",
    "    while tt > sector_range[sectors[0]][0]:\n",
    "        tt -= period\n",
    "    \n",
    "    if tt + period > sector_range[sectors[-1]][1] and warnings:\n",
    "        print(\"WARNING: period too large to fix t0\")\n",
    "    return tt + period\n",
    "\n",
    "def accept_planet(pl_data, sectors):\n",
    "    sectors = sectors if isinstance(sectors, list) else [sectors]\n",
    "    tt = fix_t0(pl_data[\"t0\"], pl_data[\"orb_period\"], sectors)\n",
    "\n",
    "    n_transits = 0\n",
    "    while tt < sector_range[sectors[-1]][1]:\n",
    "        n_transits += 1\n",
    "        tt += pl_data[\"orb_period\"]\n",
    "    if n_transits < 2:\n",
    "        return False\n",
    "    return True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_detection(detection, gt_params, sectors, per_frac=0.01, dur_factor=1):\n",
    "    \n",
    "    true_per = gt_params[\"orb_period\"]\n",
    "    true_t0 = fix_t0(gt_params[\"t0\"], true_per, sectors, warnings=1)\n",
    "    dur = gt_params[\"duration\"]\n",
    "    \n",
    "    pred_per = detection[\"period\"]\n",
    "    pred_t0 = detection[\"t0\"]\n",
    "        \n",
    "    per_correct = ((1-per_frac)*true_per <= pred_per) and (pred_per <= (1+per_frac)*true_per)\n",
    "    t0_correct = ((true_t0-0.5*dur_factor*dur) <= pred_t0) and (pred_t0 <= (true_t0+0.5*dur_factor*dur))\n",
    "    \n",
    "    return (per_correct and t0_correct), per_correct, t0_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sect = {i:{} for i in [1,2,3,4]}\n",
    "rejected_sect = {i:{} for i in [1,2,3,4]}\n",
    "\n",
    "for sector in [1,2,3,4]:\n",
    "    for s_id in pl_ids_corrected:\n",
    "        if s_id in gt_sector[sector][\"pl\"][\"params\"]:\n",
    "            targets_sect[sector][s_id] = {}\n",
    "            rejected_sect[sector][s_id] = {}\n",
    "            for pl_i, pl_data in gt_sector[sector][\"pl\"][\"params\"][s_id].items():\n",
    "                if accept_planet(pl_data, sector):\n",
    "                    targets_sect[sector][s_id][pl_i] = pl_data\n",
    "                else:\n",
    "                    rejected_sect[sector][s_id][pl_i] = pl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_detections_sect = {i:{} for i in [1,2,3,4]}\n",
    "for sector in [1,2,3,4]:\n",
    "    for s_id in pl_ids_corrected:\n",
    "        if s_id in gt_sector[sector][\"pl\"][\"params\"]:\n",
    "            pipeline_detections_sect[sector][s_id] = dv_sect[sector][s_id] if s_id in dv_sect[sector] else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_detection(params, detection, dur_factor=1, per_frac=0.01):\n",
    "    # assumes sample (params) contains single planet \n",
    "    t0_true = params[\"t0\"]\n",
    "    dur_true = params[\"duration\"]\n",
    "    per_true = params[\"period\"]\n",
    "    \n",
    "    t0_correct = (detection[\"t0\"] > (t0_true - 0.5*dur_factor*dur_true)) and \\\n",
    "                 (detection[\"t0\"] < (t0_true + 0.5*dur_factor*dur_true))\n",
    "    per_correct = (1-per_frac)*per_true < detection[\"period\"] and detection[\"period\"] < (1+per_frac)*per_true\n",
    "    correct = (t0_correct and per_correct)\n",
    "    return correct\n",
    "\n",
    "def evaluate_thresholds(detections, thresholds):\n",
    "    snames = [\"tp\", \"fp\", \"fn\", \"tn\"]\n",
    "    results = {sname:[] for sname in snames}\n",
    "    pbar = tqdm(thresholds)\n",
    "    for thr in pbar:  \n",
    "        try:\n",
    "            tp = fp = tn = fn = 0\n",
    "            for i in meta:\n",
    "                num_planets = len(meta[i])\n",
    "                found_planets = 0\n",
    "                for score, det in detections[i].items():\n",
    "                    if score >= thr:\n",
    "                        found_one = False\n",
    "                        if num_planets > 0:\n",
    "                            for pl_i in meta[i]:\n",
    "                                if correct_detection(meta[i][pl_i], det):\n",
    "                                    found_one = True\n",
    "                                    found_planets += 1\n",
    "                                    tp += 1\n",
    "                                    break\n",
    "                        if not found_one:\n",
    "                            fp += 1\n",
    "                if found_planets > num_planets:\n",
    "                    print(\"WARNING: found more planets than possible\")\n",
    "                fn += (num_planets-found_planets)\n",
    "                # true negative is always inf\n",
    "            results[\"tp\"].append(tp), results[\"fp\"].append(fp) \n",
    "            results[\"tn\"].append(tn), results[\"fn\"].append(fn) \n",
    "        except:\n",
    "            pbar.close()\n",
    "            raise\n",
    "    for sname in snames:\n",
    "        results[sname] = np.array(results[sname])\n",
    "    return result\n",
    "\n",
    "\n",
    "def concatenate_sectors(detections):\n",
    "    detections_ = {}\n",
    "    for sector in detections:\n",
    "        for s_id in detections[sector]:\n",
    "            detections_[f\"{sector}-{s_id}\"] = detections[sector][s_id]\n",
    "    return detections_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # individual sector detections\n",
    "\n",
    "# pipeline_results = {}\n",
    "# for sector in [1,2,3,4]:\n",
    "#     sector_results = {\"sampleids\":[], \"planets\":[], \"detected\":[], \"tp\":[], \"fn\":[], \"fp\":[]}\n",
    "#     pipeline_results[sector] = sector_results\n",
    "#     for s_id in pl_ids_corrected:\n",
    "#         if s_id in gt_sector[sector][\"pl\"][\"params\"]:\n",
    "#             sector_results[\"sampleids\"].append(s_id)\n",
    "#             accepted_planets = []\n",
    "#             detected_planets = []\n",
    "#             tp = fp = fn = 0\n",
    "#             for pl_i, pl_data in gt_sector[sector][\"pl\"][\"params\"][s_id].items():\n",
    "#                 if accept_planet(pl_data, sector):\n",
    "#                     detected = False\n",
    "#                     accepted_planets.append(pl_i)\n",
    "                    \n",
    "#                     if s_id in dv_sect[sector]:\n",
    "#                         if correct_detection(dv_sect[sector][s_id], pl_data, sector)[0]:\n",
    "#                             detected_planets.append(pl_i)\n",
    "#                             detected = True\n",
    "#                             tp += 1\n",
    "#                     if not detected:\n",
    "#                         fn += 1\n",
    "#             fp = 1 if ((s_id in dv_sect[sector]) and len(detected_planets)==0\\\n",
    "#                        and dv_sect[sector][s_id][\"n_transit\"]>=3) else 0\n",
    "                        \n",
    "#             sector_results[\"planets\"].append(accepted_planets)\n",
    "#             sector_results[\"detected\"].append(detected_planets)\n",
    "#             sector_results[\"tp\"].append(tp), sector_results[\"fp\"].append(fp), \n",
    "#             sector_results[\"fn\"].append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"s  tp  fp  fn\")\n",
    "for i in [1,2,3,4]:\n",
    "    print(i,\"\", sum(pipeline_results[i][\"tp\"]), sum(pipeline_results[i][\"fp\"]), sum(pipeline_results[i][\"fn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_path = \"data/eval/lilith/processed_bls_12h_outlier\"\n",
    "# write_path = \"results/bls_multi_3it_outlier_detections\"\n",
    "\n",
    "# fnames = [fnm for fnm in os.listdir(load_path) if not fnm.startswith(\".\")]\n",
    "# utils.make_dir(write_path)\n",
    "# pbar = tqdm(fnames)\n",
    "# for fname in pbar:\n",
    "#     try:\n",
    "#         bls_detections = {i:{} for i in [1,2,3,4,0]}\n",
    "#         batch = dl.load_data(load_path + \"/\"+ fname)\n",
    "#         if batch is None:\n",
    "#             continue\n",
    "        \n",
    "#         for sampleid in batch:\n",
    "#             if sampleid in pl_ids_corrected:\n",
    "#                 for i in range(len(batch[sampleid][\"time\"])):\n",
    "#                     time = batch[sampleid][\"time\"][i]\n",
    "#                     sector = retrieve_sector(time)\n",
    "#                     flat = batch[sampleid][\"flux\"][i]\n",
    "#                     detections = bls_det.algorithm(time, flat, num_iters=3)\n",
    "#                     bls_detections[sector][sampleid] = detections\n",
    "\n",
    "# #                 if consec[sampleid]:\n",
    "# #                     time = np.concatenate(batch[sampleid][\"time\"])\n",
    "# #                     flat = np.concatenate(batch[sampleid][\"flux\"])\n",
    "# #                     detections = bls_det.algorithm(time, flat, min_transits=5, num_iters=3, freq_fac=6)\n",
    "# #                     bls_detections[0][sampleid] = detections\n",
    "#         with open(write_path + \"/\" +fname, \"wb\") as f:\n",
    "#             pickle.dump(bls_detections, f) \n",
    "#     except:\n",
    "#         pbar.close()\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine bls_detections\n",
    "# bls_detections_sect = {i:{s_id:{} for s_id in targets_sect[i]} for i in [1,2,3,4]}\n",
    "# for fnm in os.listdir(\"results/bls_multi_3it_detections\"):\n",
    "#     with open(\"results/bls_multi_3it_detections/\"+fnm, \"rb\") as f:\n",
    "#         b = pickle.load(f)\n",
    "#     for i in [1,2,3,4]:\n",
    "#         bls_detections_sect[i] = {**bls_detections_sect[i], **b[i]}\n",
    "# with open(\"results/bls_multi_3it_detections.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(bls_detections_sect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [1:16:16<18:25, 276.42s/it]"
     ]
    }
   ],
   "source": [
    "rnn_detections_sect = {i:{s_id:{} for s_id in targets_sect[i]} for i in [1,2,3,4]}\n",
    "pbar = tqdm(os.listdir(\"data/eval/lilith/nn_basic_pts\"))\n",
    "for fnm in pbar:\n",
    "    try:\n",
    "        if not fnm.startswith(\".\"):\n",
    "            with open(\"data/eval/lilith/nn_basic_pts/\"+fnm, \"rb\") as f:\n",
    "                b_pts = pickle.load(f)\n",
    "            with open(\"data/eval/lilith/processed_nn_basic/\"+fnm, \"rb\") as f:\n",
    "                b = pickle.load(f)\n",
    "\n",
    "            for s_id in b:\n",
    "                for i in range(len(b[s_id][\"time\"])):\n",
    "                    sector = retrieve_sector(b[s_id][\"time\"][i])\n",
    "                    detected = rnn_det.algorithm1(b_pts[s_id][i].copy(), num_iters=3, \n",
    "                                                  min_transits=3, p_min=2, p_max=None, step_mult=2, \n",
    "                                                  smooth=True, peak_frac=2, show_steps=False)\n",
    "                    rnn_detections_sect[sector][s_id] = detected\n",
    "    except:\n",
    "        pbar.close()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "with open(\"results/rnn_multi_3it_detections.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rnn_detections_sect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
