{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"descended\" not in locals():\n",
    "    descended = 1\n",
    "    %cd \"..\"\n",
    "    \n",
    "import utils\n",
    " \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "from dataloading import loading as load\n",
    "from training.nn_models import MLPmodel, CNNmodel, NaiveRNNmodel, RNNmodel, num_params\n",
    "from training.trainer_class import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(dic, keys, lbls=None, lbl_prepend=\"\", valid_only=False, train_only=False, snr_range=None, \n",
    "               lstyle=\"-\", return_c=False):\n",
    "    # for plotting training statistics for single run\n",
    "    keys = keys if isinstance(keys, list) else [keys]\n",
    "    labels = keys if lbls is None else lbls\n",
    "    for key, lbl in zip(keys, labels):\n",
    "        train = dic[\"train\"][key] if snr_range is None else dic[\"train\"][snr_range][key]\n",
    "        valid = dic[\"valid\"][key] if snr_range is None else dic[\"valid\"][snr_range][key]\n",
    "        p = plt.plot(train, label=lbl_prepend+lbl, linestyle=lstyle) if not valid_only else plt.plot([], label=lbl_prepend+lbl)\n",
    "        plt.plot(valid, color=p[0].get_color(), linestyle=\"--\" if not valid_only else lstyle) if not train_only else 0\n",
    "    plt.xticks(fontsize=14), plt.yticks(fontsize=14)\n",
    "    return p[0].get_color() if return_c else None\n",
    "\n",
    "def save_trainer_stats(trainer):\n",
    "    # copies trainer tracked values (loss, accuracies, etc.)\n",
    "    stats = {s:{\"train\":{}, \"valid\":{}} for s in [\"losses\", \"metrics\"]}\n",
    "    splitnames = [\"train\", \"valid\"]\n",
    "    for s in splitnames:\n",
    "        stats[\"metrics\"][s] = {rng:{} for rng in trainer.snr_ranges}\n",
    "        for l in trainer.losses[s]:\n",
    "            stats[\"losses\"][s][l] = [i for i in trainer.losses[s][l]]\n",
    "        for rng in stats[\"metrics\"][s]:\n",
    "            for m in trainer.metrics[s][rng]:\n",
    "                stats[\"metrics\"][s][rng][m] = [i for i in trainer.metrics[s][rng][m]]\n",
    "    if \"test\" in trainer.metrics:\n",
    "        stats[\"metrics\"][\"test\"] = {rng:{} for rng in trainer.snr_ranges}\n",
    "        for rng in stats[\"metrics\"][\"test\"]:\n",
    "            for m in trainer.metrics[\"test\"][rng]:\n",
    "                stats[\"metrics\"][\"test\"][rng][m] = trainer.metrics[\"test\"][rng][m]\n",
    "    if trainer.lambdas is not None:\n",
    "        stats[\"lambdas\"] = [i for i in trainer.lambdas]\n",
    "    stats[\"grad_norms\"] = [i for i in trainer.grad_norms]\n",
    "    return stats\n",
    "\n",
    "def save_results(trainer, fname):\n",
    "    utils.make_dir(\"results\")\n",
    "    with open(\"results/\"+fname, \"wb\") as f:\n",
    "        pickle.dump(save_trainer_stats(trainer), f)\n",
    "        \n",
    "def average_stats(stats):\n",
    "    # in the case for multiple runs\n",
    "    runs = len(stats)\n",
    "    stats_mean, stats_std = {}, {}\n",
    "\n",
    "    grad_norms = [stats[i][\"grad_norms\"] for i in range(runs)]\n",
    "    stats_mean[\"grad_norms\"] = np.mean(grad_norms, 0)\n",
    "    stats_std[\"grad_norms\"] = np.std(grad_norms, 0)\n",
    "\n",
    "    #metrics\n",
    "    stats_mean[\"metrics\"], stats_std[\"metrics\"] = {}, {}\n",
    "    for split in stats[0][\"metrics\"].keys():\n",
    "        stats_mean[\"metrics\"][split], stats_std[\"metrics\"][split] = {}, {}\n",
    "        for rng in stats[0][\"metrics\"][\"train\"].keys():\n",
    "            stats_mean[\"metrics\"][split][rng], stats_std[\"metrics\"][split][rng] = {}, {}\n",
    "            for m in stats[0][\"metrics\"][\"train\"][rng].keys():\n",
    "                mvals = [stats[i][\"metrics\"][split][rng][m] for i in range(runs)]\n",
    "                stats_mean[\"metrics\"][split][rng][m] = np.mean(mvals, 0)\n",
    "                stats_std[\"metrics\"][split][rng][m] = np.std(mvals, 0)\n",
    "    #losses\n",
    "    stats_mean[\"losses\"], stats_std[\"losses\"] = {}, {}\n",
    "    for split in [\"train\", \"valid\"]:\n",
    "        stats_mean[\"losses\"][split], stats_std[\"losses\"][split] = {}, {}\n",
    "        for l in stats[0][\"losses\"][\"train\"].keys():\n",
    "            lvals = [stats[i][\"losses\"][split][l] for i in range(runs)]\n",
    "            stats_mean[\"losses\"][split][l] = np.mean(lvals, 0)\n",
    "            stats_std[\"losses\"][split][l] = np.std(lvals, 0)\n",
    "    return stats_mean, stats_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modes: 0:nothing, 1:scale, 2:scale+diff, 3:diff+scale\n",
    "# nanmodes: 0:nothing, 1:zero-fill, 2:lin_interp\n",
    "\n",
    "# NOTE: median scaled here - note: if rnn applied real-world light curve, \n",
    "#                            need to take into large deviations from center\n",
    "train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "                                          valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "                                          train_batch=128, valid_batch=1000, mode=1, nanmode=2,\n",
    "                                          scale_median=1, standardize=1, incl_centr=False)\n",
    "\n",
    "train500_loader, valid500_loader, test500_loader = load.get_loaders_fn(train_path=\"data/nn/sim500/train\", \n",
    "                                                valid_path=\"data/nn/sim500/valid\", test_path=\"data/nn/sim500/test\",\n",
    "                                                train_batch=128, valid_batch=1000, mode=1, \n",
    "                                                nanmode=2, scale_median=1, standardize=1, incl_centr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Train each model 3 times for different random seeds, then store the results for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 204609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:12<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# # MLP =======================\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = MLPmodel(n_inputs=1500, hidden_units=[128,64,64], neg_slope=0)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"mlp\")\n",
    "#     trainer.train(epochs=25, lr=0.005, weight_decay=5e-3)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "# stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/mlp_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = MLPmodel(n_inputs=500, hidden_units=[128,64,64], neg_slope=0)\n",
    "#     trainer = Trainer(model, train500_loader, valid500_loader, mname=\"mlp\")\n",
    "#     trainer.train(epochs=25, lr=0.005, weight_decay=5e-3)\n",
    "#     trainer.get_test_results(test500_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "# stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/mlp_sim500.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 inputs left after conv layers\n",
      "params: 3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:46<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# # CNN =======================\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = CNNmodel(1500, channels=[4,12,1], kernels=[7,7,3],\n",
    "#                strides=[1,1,1], fc_hiddens=[48], pool=3, batch_norm=True, info=False)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"cnn\")\n",
    "#     trainer.train(epochs=25, lr=0.006, weight_decay=1e-4)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "# stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/cnn_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = CNNmodel(500, channels=[4,12,1], kernels=[7,7,3],\n",
    "#                strides=[1,1,1], fc_hiddens=[48], pool=3, batch_norm=True, info=False)\n",
    "#     trainer = Trainer(model, train500_loader, valid500_loader, mname=\"cnn\")\n",
    "#     trainer.train(epochs=25, lr=0.006, weight_decay=1e-4)\n",
    "#     trainer.get_test_results(test500_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "# stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/cnn_sim500.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NaiveRNN =======================\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = NaiveRNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn_naive\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=1e-4)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/rnn_naive_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = NaiveRNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train500_loader, valid500_loader, mname=\"rnn_naive\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=1e-4)\n",
    "#     trainer.get_test_results(test500_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/rnn_naive_sim500.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN =======================\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=2)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru2_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=False, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/gru1_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=True, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bilstm1_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train500_loader, valid500_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test500_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_sim500.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "\n",
    "# stats = [] \n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=True, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train500_loader, valid500_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "#     trainer.get_test_results(test500_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bilstm1_sim500.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is unbalanced\n",
    "tr = np.sum(train_loader.dataset.mask.numpy().astype(bool))  # num transit time steps\n",
    "nontr = np.sum(~train_loader.dataset.mask.numpy().astype(bool))  # num other time steps\n",
    "print(\"non-transit / transit =\", nontr/tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=12.6, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_w12.6_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=None)\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_w4_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"sqrt\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_w4sqrt_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_w4snr_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_wsnr_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)\n",
    "\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=\"sqrt\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "# with open(\"results/training/bigru1_wsqrt_sim.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_conf = nn_models.ConfidenceRNNmodel(64, [64,64], [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "# rnn_conf_trainer = Trainer(rnn_conf, train_loader, valid_loader, mname=\"rnn_conf\")\n",
    "# print(\"params:\", num_params(rnn_conf))\n",
    "# rnn_conf_trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_gen = nn_models.GenerativeRNNmodel(64, [64,64], [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "# rnn_gen_trainer = Trainer(rnn_gen, train_loader, valid_loader, mname=\"rnn_gen\")\n",
    "# print(\"params:\", num_params(rnn_gen))\n",
    "# rnn_gen_trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (n)ot median (s)caled\n",
    "train_ns_loader, valid_ns_loader, _ = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "                                          valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "                                          train_batch=128, valid_batch=1000, mode=1, nanmode=2,\n",
    "                                          scale_median=0, standardize=1, incl_centr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0), np.random.seed(0)\n",
    "# model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "# trainer = Trainer(model, train_ns_loader, valid_ns_loader, mname=\"rnn\")\n",
    "# trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=None)\n",
    "# torch.save(model, \"models/bigru1_sim.pt\")\n",
    "\n",
    "# torch.manual_seed(0), np.random.seed(0)\n",
    "# model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "# trainer = Trainer(model, train_ns_loader, valid_ns_loader, mname=\"rnn\")\n",
    "# trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"sqrt\")\n",
    "# torch.save(model, \"models/bigru1_w4sqrt_sim.pt\")\n",
    "\n",
    "# torch.manual_seed(0), np.random.seed(0)\n",
    "# model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "# trainer = Trainer(model, train_ns_loader, valid_ns_loader, mname=\"rnn\")\n",
    "# trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=None, snr_weight=\"sqrt\")\n",
    "# torch.save(model, \"models/bigru1_wsqrt_sim.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no median scaling, standardizing, mode 1, nanmode 0\n",
    "# train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "#                                           valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "#                                           train_batch=128, valid_batch=1000, mode=1, nanmode=0,\n",
    "#                                           scale_median=0, standardize=1, incl_centr=False)\n",
    "# fname = \"bigru1_w4snr_sim_mscale0_stddize1_mode1_nanmode0\"\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "#     if i==0:\n",
    "#         torch.save(model, \"models/\"+fname+\".pt\")\n",
    "# with open(\"results/preprocessing/\"+fname+\".pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # median scaling, standardizing, mode 1, nanmode 0\n",
    "# train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "#                                           valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "#                                           train_batch=128, valid_batch=1000, mode=1, nanmode=0,\n",
    "#                                           scale_median=1, standardize=1, incl_centr=False)\n",
    "\n",
    "# fname = \"bigru1_w4snr_sim_mscale1_stddize1_mode1_nanmode0\"\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "#     if i==0:\n",
    "#         torch.save(model, \"models/\"+fname+\".pt\")\n",
    "# with open(\"results/preprocessing/\"+fname+\".pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # median scaling, standardizing, mode 0, nanmode 0\n",
    "# train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "#                                           valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "#                                           train_batch=128, valid_batch=1000, mode=0, nanmode=0,\n",
    "#                                           scale_median=1, standardize=1, incl_centr=False)\n",
    "\n",
    "# fname = \"bigru1_w4snr_sim_mscale1_stddize1_mode0_nanmode0\"\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "#     if i==0:\n",
    "#         torch.save(model, \"models/\"+fname+\".pt\")\n",
    "# with open(\"results/preprocessing/\"+fname+\".pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no median scaling, standardizing, mode 2, nanmode 0\n",
    "# train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "#                                           valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "#                                           train_batch=128, valid_batch=1000, mode=2, nanmode=0,\n",
    "#                                           scale_median=0, standardize=1, incl_centr=False)\n",
    "\n",
    "# fname = \"bigru1_w4snr_sim_mscale0_stddize1_mode2_nanmode0\"\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "#     if i==0:\n",
    "#         torch.save(model, \"models/\"+fname+\".pt\")\n",
    "# with open(\"results/preprocessing/\"+fname+\".pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no median scaling, standardizing, mode 3, nanmode 0\n",
    "# train_loader, valid_loader, test_loader = load.get_loaders_fn(train_path=\"data/nn/sim/train\", \n",
    "#                                           valid_path=\"data/nn/sim/valid\", test_path=\"data/nn/sim/test\",\n",
    "#                                           train_batch=128, valid_batch=1000, mode=3, nanmode=0,\n",
    "#                                           scale_median=0, standardize=1, incl_centr=False)\n",
    "\n",
    "# fname = \"bigru1_w4snr_sim_mscale0_stddize1_mode3_nanmode0\"\n",
    "# stats = []\n",
    "# for i in range(3):\n",
    "#     torch.manual_seed(i), np.random.seed(i) \n",
    "#     model = RNNmodel(64, [64,64], neg_slope=0, lstm=False, bidirectional=True, num_layers=1)\n",
    "#     trainer = Trainer(model, train_loader, valid_loader, mname=\"rnn\")\n",
    "#     trainer.train(epochs=25, lr=0.008, weight_decay=5e-5, transit_weight=4, snr_weight=\"snr\")\n",
    "#     trainer.get_test_results(test_loader)\n",
    "#     stats.append(save_trainer_stats(trainer))\n",
    "#     stats_mean, stats_std = average_stats(stats)\n",
    "#     if i==0:\n",
    "#         torch.save(model, \"models/\"+fname+\".pt\")\n",
    "# with open(\"results/preprocessing/\"+fname+\".pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\"mean\":stats_mean, \"std\":stats_std}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
